{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0e9a0b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting clean-text\n",
      "  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
      "Collecting emoji<2.0.0,>=1.0.0\n",
      "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
      "     -------------------------------------- 175.4/175.4 kB 3.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting ftfy<7.0,>=6.0\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 53.1/53.1 kB ? eta 0:00:00\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\cloudseals\\anaconda3\\lib\\site-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.5)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171032 sha256=deab6e50cb087cbf0735d93375ffe6ffbfde69c131504fe11ec3cf4619a85220\n",
      "  Stored in directory: c:\\users\\cloudseals\\appdata\\local\\pip\\cache\\wheels\\fa\\7a\\e9\\22dd0515e1bad255e51663ee513a2fa839c95934c5fc301090\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji, ftfy, clean-text\n",
      "Successfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install clean-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a52a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d33cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\CLOUDSEALS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langdetect import detect\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import plotly.express as px\n",
    "import yfinance as yf\n",
    "# NLTK VADER for sentiment analysis\n",
    "import dateparser\n",
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a186ce7b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-14T07:11:48.723049Z",
     "iopub.status.busy": "2021-07-14T07:11:48.721778Z",
     "iopub.status.idle": "2021-07-14T07:11:48.747842Z",
     "shell.execute_reply": "2021-07-14T07:11:48.748236Z",
     "shell.execute_reply.started": "2021-07-14T06:36:54.148346Z"
    },
    "papermill": {
     "duration": 0.046063,
     "end_time": "2021-07-14T07:11:48.748459",
     "exception": false,
     "start_time": "2021-07-14T07:11:48.702396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed8a44b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "URL = 'https://www1.nseindia.com/content/indices/ind_nifty50list.csv'\n",
    "df = pd.read_csv(URL, index_col = 'Company Name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c2c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "News_data = pd.DataFrame()\n",
    "for stock_symbol in list(df['Symbol']):\n",
    "# Set the stock symbol for which you want to fetch the news    \n",
    "    # Set the Google News API endpoint URL and parameters\n",
    "    api_url = 'https://newsapi.org/v2/everything'\n",
    "    params = {\n",
    "        'q': stock_symbol,\n",
    "        'sortBy': 'publishedAt',\n",
    "        'language': 'en',\n",
    "        'apiKey': '2abb9ff888b64e3eb54f292f42e8da91' # Replace with your API key\n",
    "    }\n",
    "\n",
    "    # Make a GET request to the API endpoint with the specified parameters\n",
    "    response = requests.get(api_url, params=params)\n",
    "\n",
    "    # Parse the JSON response content\n",
    "    news_data = json.loads(response.content)\n",
    "\n",
    "    # Print the latest news articles related to the stock symbol\n",
    "    for article in news_data['articles']:\n",
    "        article.pop('source')\n",
    "        data = pd.DataFrame(article, index=[0])\n",
    "        News_data = pd.concat([News_data,data])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5907425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1974, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "News_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e1caab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e289f370",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df486fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "News_data= News_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade4c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "News_data['content'] = [News_data['content'][i][:-15] for i in range(len(News_data['content']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b84c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in News_data.columns:\n",
    "    News_data[column] =News_data[column].astype(str)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4179f3",
   "metadata": {},
   "source": [
    "# Get scores using NLTk sentiment intensity analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "literary-building",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-14T07:11:49.078573Z",
     "iopub.status.busy": "2021-07-14T07:11:49.070772Z",
     "iopub.status.idle": "2021-07-14T07:11:49.112382Z",
     "shell.execute_reply": "2021-07-14T07:11:49.111899Z",
     "shell.execute_reply.started": "2021-07-14T06:36:54.381143Z"
    },
    "papermill": {
     "duration": 0.074693,
     "end_time": "2021-07-14T07:11:49.112482",
     "exception": false,
     "start_time": "2021-07-14T07:11:49.037789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_news(News_data):\n",
    "    # Instantiate the sentiment intensity analyzer\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "    News_data['News'] = News_data['title']+ News_data['description'] + News_data['content']\n",
    "    News_data = News_data.drop(['title','description','content'],axis=1)\n",
    "    # Iterate through the headlines and get the polarity scores using vader\n",
    "    scores = News_data['News'].apply(vader.polarity_scores).tolist()\n",
    "\n",
    "    # Convert the 'scores' list of dicts into a DataFrame\n",
    "    scores_df = pd.DataFrame(scores)\n",
    "    News_data = News_data.sort_values('publishedAt')\n",
    "    # Join the DataFrames of the news and the list of dicts\n",
    "    parsed_and_scored_news = News_data.join(scores_df, rsuffix='_right')        \n",
    "    parsed_and_scored_news = parsed_and_scored_news.set_index('publishedAt')             \n",
    "    parsed_and_scored_news = parsed_and_scored_news.rename(columns={\"compound\": \"sentiment_score\"})\n",
    "\n",
    "    return parsed_and_scored_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "amateur-wheat",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-14T07:11:49.155152Z",
     "iopub.status.busy": "2021-07-14T07:11:49.154398Z",
     "iopub.status.idle": "2021-07-14T07:11:49.175427Z",
     "shell.execute_reply": "2021-07-14T07:11:49.175037Z",
     "shell.execute_reply.started": "2021-07-14T06:36:54.436459Z"
    },
    "papermill": {
     "duration": 0.047316,
     "end_time": "2021-07-14T07:11:49.175550",
     "exception": false,
     "start_time": "2021-07-14T07:11:49.128234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "News_data_lable = score_news(News_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53f4e446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'author', 'url', 'urlToImage', 'News', 'neg', 'neu', 'pos',\n",
       "       'sentiment_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "News_data_lable.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5496258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "News_data_lable = News_data_lable.drop(['index', 'author', 'url', 'urlToImage','neg','neu','pos'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d387fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "News_data_lable['Label'] = [1 if i>0 else 0 for i in list(News_data_lable['sentiment_score'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c35a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "empirical-driving",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-14T07:11:50.037666Z",
     "iopub.status.busy": "2021-07-14T07:11:50.027334Z",
     "iopub.status.idle": "2021-07-14T07:11:50.426716Z",
     "shell.execute_reply": "2021-07-14T07:11:50.426316Z",
     "shell.execute_reply.started": "2021-07-14T06:43:16.869014Z"
    },
    "papermill": {
     "duration": 0.424872,
     "end_time": "2021-07-14T07:11:50.426825",
     "exception": false,
     "start_time": "2021-07-14T07:11:50.001953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "headlines = News_data_lable['News']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc2fb8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "publishedAt\n",
       "2023-02-19T06:09:15Z    Upgrade error from mysql 5.7 to 8.0Добрый день...\n",
       "2023-02-19T12:54:48Z    Trade setup for Monday: Top 15 things to know ...\n",
       "2023-02-19T15:54:27Z    Capgemini: Going 'LONG' On EU Quality For 2023...\n",
       "2023-02-19T19:32:29Z    Forecasters warn 800 mile-wide 'Greenland Barr...\n",
       "2023-02-19T20:46:57Z    Power restored to all homes after Storm Otto m...\n",
       "                                              ...                        \n",
       "2023-03-19T06:05:36Z    django.core.serializers.base.DeserializationEr...\n",
       "2023-03-19T06:07:59Z    Soldier recalls horror of squad shooting dead ...\n",
       "2023-03-19T06:10:08Z    Delhi Lt Governor Flags Off G20 Cyclothon Rall...\n",
       "2023-03-19T06:14:02Z    TEUCER M2-LD02 PCIe NVMe M.2 2280 SSD Double S...\n",
       "2023-03-19T06:18:00Z    In line with new govt rules, Reliance re-aucti...\n",
       "Name: News, Length: 1974, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "material-crowd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-14T07:11:50.467119Z",
     "iopub.status.busy": "2021-07-14T07:11:50.466472Z",
     "iopub.status.idle": "2021-07-14T07:11:50.469109Z",
     "shell.execute_reply": "2021-07-14T07:11:50.469598Z",
     "shell.execute_reply.started": "2021-07-14T06:43:18.969101Z"
    },
    "papermill": {
     "duration": 0.025005,
     "end_time": "2021-07-14T07:11:50.469769",
     "exception": false,
     "start_time": "2021-07-14T07:11:50.444764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "headlines = [clean(headline.lower()) for headline in headlines] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f45b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "News_data_lable['News']=headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb04c786",
   "metadata": {},
   "source": [
    "# Feature extraction from text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62119d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e852070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## implement BAG OF WORDS\n",
    "countvector=CountVectorizer(ngram_range=(2,2))\n",
    "X=countvector.fit_transform(headlines)\n",
    "Y=News_data_lable['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6009c9bd",
   "metadata": {},
   "source": [
    "# Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a028ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-confirmation",
   "metadata": {
    "papermill": {
     "duration": 0.027166,
     "end_time": "2021-07-14T07:11:50.524645",
     "exception": false,
     "start_time": "2021-07-14T07:11:50.497479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "unauthorized-holiday",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-14T07:11:50.581402Z",
     "iopub.status.busy": "2021-07-14T07:11:50.580752Z",
     "iopub.status.idle": "2021-07-14T07:11:51.683248Z",
     "shell.execute_reply": "2021-07-14T07:11:51.683620Z",
     "shell.execute_reply.started": "2021-07-14T06:47:22.687673Z"
    },
    "papermill": {
     "duration": 1.13259,
     "end_time": "2021-07-14T07:11:51.683758",
     "exception": false,
     "start_time": "2021-07-14T07:11:50.551168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "elder-record",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-14T07:11:55.568956Z",
     "iopub.status.busy": "2021-07-14T07:11:55.568511Z",
     "iopub.status.idle": "2021-07-14T07:12:15.693721Z",
     "shell.execute_reply": "2021-07-14T07:12:15.693224Z",
     "shell.execute_reply.started": "2021-07-14T06:50:37.622847Z"
    },
    "papermill": {
     "duration": 20.145182,
     "end_time": "2021-07-14T07:12:15.693829",
     "exception": false,
     "start_time": "2021-07-14T07:11:55.548647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement RandomForest Classifier\n",
    "Model=LogisticRegression()\n",
    "Model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-billion",
   "metadata": {
    "papermill": {
     "duration": 0.019103,
     "end_time": "2021-07-14T07:12:15.731827",
     "exception": false,
     "start_time": "2021-07-14T07:12:15.712724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test data preprocessing and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caroline-validation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-14T07:12:15.796971Z",
     "iopub.status.busy": "2021-07-14T07:12:15.786366Z",
     "iopub.status.idle": "2021-07-14T07:12:16.434631Z",
     "shell.execute_reply": "2021-07-14T07:12:16.434077Z",
     "shell.execute_reply.started": "2021-07-14T06:54:23.046253Z"
    },
    "papermill": {
     "duration": 0.68449,
     "end_time": "2021-07-14T07:12:16.434763",
     "exception": false,
     "start_time": "2021-07-14T07:12:15.750273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Predict for the Test Dataset\n",
    "\n",
    "predictions = Model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-target",
   "metadata": {
    "papermill": {
     "duration": 0.027864,
     "end_time": "2021-07-14T07:12:16.491388",
     "exception": false,
     "start_time": "2021-07-14T07:12:16.463524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "contemporary-break",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-14T07:12:16.551649Z",
     "iopub.status.busy": "2021-07-14T07:12:16.551168Z",
     "iopub.status.idle": "2021-07-14T07:12:16.555074Z",
     "shell.execute_reply": "2021-07-14T07:12:16.554555Z",
     "shell.execute_reply.started": "2021-07-14T06:54:44.397000Z"
    },
    "papermill": {
     "duration": 0.035524,
     "end_time": "2021-07-14T07:12:16.555203",
     "exception": false,
     "start_time": "2021-07-14T07:12:16.519679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Import library to check accuracy\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cleared-institute",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-14T07:12:16.594856Z",
     "iopub.status.busy": "2021-07-14T07:12:16.594427Z",
     "iopub.status.idle": "2021-07-14T07:12:16.610373Z",
     "shell.execute_reply": "2021-07-14T07:12:16.609880Z",
     "shell.execute_reply.started": "2021-07-14T06:54:46.359659Z"
    },
    "papermill": {
     "duration": 0.036626,
     "end_time": "2021-07-14T07:12:16.610475",
     "exception": false,
     "start_time": "2021-07-14T07:12:16.573849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 80  63]\n",
      " [ 14 238]]\n",
      "0.8050632911392405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.56      0.68       143\n",
      "           1       0.79      0.94      0.86       252\n",
      "\n",
      "    accuracy                           0.81       395\n",
      "   macro avg       0.82      0.75      0.77       395\n",
      "weighted avg       0.81      0.81      0.79       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix=confusion_matrix(y_test,predictions)\n",
    "print(matrix)\n",
    "score=accuracy_score(y_test,predictions)\n",
    "print(score)\n",
    "report=classification_report(y_test,predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eecc66b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "#Save model in h5 file\n",
    "filename = \"Completed_model.joblib\"\n",
    "vector_filename = \"vector_filename.joblib\"\n",
    "joblib.dump(Model, filename)\n",
    "joblib.dump(countvector,vector_filename)\n",
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "loaded_model = joblib.load(filename)\n",
    "loaded_Vector = joblib.load(vector_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d3a187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "News_data = pd.DataFrame()\n",
    "api_url = 'https://newsapi.org/v2/everything'\n",
    "params = {\n",
    "    'q': 'JSL',\n",
    "    'sortBy': 'publishedAt',\n",
    "    'language': 'en',\n",
    "    'apiKey': '2abb9ff888b64e3eb54f292f42e8da91' # Replace with your API key\n",
    "}\n",
    "\n",
    "# Make a GET request to the API endpoint with the specified parameters\n",
    "response = requests.get(api_url, params=params)\n",
    "\n",
    "# Parse the JSON response content\n",
    "news_data = json.loads(response.content)\n",
    "\n",
    "# Print the latest news articles related to the stock symbol\n",
    "for article in news_data['articles']:\n",
    "    article.pop('source')\n",
    "    data = pd.DataFrame(article, index=[0])\n",
    "    News_data = pd.concat([News_data,data])\n",
    "\n",
    "News_data= News_data.reset_index()\n",
    "News_data['content'] = [News_data['content'][i][:-15] for i in range(len(News_data['content']))]\n",
    "for column in News_data.columns:\n",
    "    News_data[column] =News_data[column].astype(str)\n",
    " \n",
    "\n",
    "\n",
    "News_data_lable = score_news(News_data)\n",
    "News_data_lable = News_data_lable.drop(['index', 'author', 'url', 'urlToImage','neg','neu','pos'],axis=1)\n",
    "News_data_lable['Label'] = [1 if i>0 else 0 for i in list(News_data_lable['sentiment_score'])]\n",
    "headlines = News_data_lable['News']\n",
    "headlines = [clean(headline.lower()) for headline in headlines] \n",
    "News_data_lable['News']=headlines\n",
    "#countvector=CountVectorizer(ngram_range=(2,2))\n",
    "X=loaded_Vector.fit_transform(headlines)\n",
    "Y=News_data_lable['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af53cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## implement BAG OF WORDS\n",
    "#countvector=CountVectorizer(ngram_range=(2,2))\n",
    "X1=loaded_Vector.transform(headlines)\n",
    "Y=News_data_lable['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb537a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1889fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = loaded_model.predict(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd6e9fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c0e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5b63a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9686509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  9]\n",
      " [ 0 14]]\n",
      "0.625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.18        10\n",
      "           1       0.61      1.00      0.76        14\n",
      "\n",
      "    accuracy                           0.62        24\n",
      "   macro avg       0.80      0.55      0.47        24\n",
      "weighted avg       0.77      0.62      0.52        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix=confusion_matrix(Y,predictions1)\n",
    "print(matrix)\n",
    "score=accuracy_score(Y,predictions1)\n",
    "print(score)\n",
    "report=classification_report(Y,predictions1)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae27e703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad1ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "occupied-metallic",
   "metadata": {
    "papermill": {
     "duration": 0.018193,
     "end_time": "2021-07-14T07:12:16.647354",
     "exception": false,
     "start_time": "2021-07-14T07:12:16.629161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Best Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34dbed86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "responsible-calcium",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-14T07:12:16.688171Z",
     "iopub.status.busy": "2021-07-14T07:12:16.687727Z",
     "iopub.status.idle": "2021-07-14T07:12:16.874560Z",
     "shell.execute_reply": "2021-07-14T07:12:16.874051Z",
     "shell.execute_reply.started": "2021-07-14T07:01:14.908999Z"
    },
    "papermill": {
     "duration": 0.20901,
     "end_time": "2021-07-14T07:12:16.874672",
     "exception": false,
     "start_time": "2021-07-14T07:12:16.665662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CLOUDSEALS\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 83.42%\n",
      "Precision: 80.62%\n",
      "Recall: 95.49%\n",
      "F1 Score: 87.43%\n",
      "\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 80.69%\n",
      "Precision: 76.43%\n",
      "Recall: 98.36%\n",
      "F1 Score: 86.02%\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 78.96%\n",
      "Precision: 75.40%\n",
      "Recall: 96.72%\n",
      "F1 Score: 84.74%\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 76.49%\n",
      "Precision: 73.07%\n",
      "Recall: 96.72%\n",
      "F1 Score: 83.25%\n",
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Accuracy: 65.10%\n",
      "Precision: 90.55%\n",
      "Recall: 47.13%\n",
      "F1 Score: 61.99%\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 78.47%\n",
      "Precision: 77.74%\n",
      "Recall: 90.16%\n",
      "F1 Score: 83.49%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "# Define the models to be trained\n",
    "models = [LogisticRegression(), SVC(), RandomForestClassifier(), GradientBoostingClassifier(), KNeighborsClassifier(), DecisionTreeClassifier()]\n",
    "model_names = [\"Logistic Regression\", \"Support Vector Classifier\", \"Random Forest\", \"Gradient Boosting\", \"K-Nearest Neighbors\", \"Decision Tree\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val\n",
    "\n",
    "results=[]\n",
    "# Train each model and get predictions\n",
    "for model, model_name in zip(models, model_names):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_val)\n",
    "    \n",
    "    # Calculate evaluation metrics for each model\n",
    "    accuracy = accuracy_score(y_val, predictions)\n",
    "    precision = precision_score(y_val, predictions)\n",
    "    recall = recall_score(y_val, predictions)\n",
    "    f1 = f1_score(y_val, predictions)\n",
    "    \n",
    "    # Store the results of each model in the results list\n",
    "    results.append((model_name, accuracy, precision, recall, f1))\n",
    "    \n",
    "# Print the results\n",
    "for result in results:\n",
    "    print(\"Model: {}\\nAccuracy: {:.2f}%\\nPrecision: {:.2f}%\\nRecall: {:.2f}%\\nF1 Score: {:.2f}%\\n\".format(result[0], result[1]*100, result[2]*100, result[3]*100, result[4]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b864d991",
   "metadata": {},
   "source": [
    "# Save Model and Reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "statistical-workplace",
   "metadata": {
    "papermill": {
     "duration": 0.018033,
     "end_time": "2021-07-14T07:12:16.911743",
     "exception": false,
     "start_time": "2021-07-14T07:12:16.893710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "#Save model in h5 file\n",
    "filename = \"Completed_model.joblib\"\n",
    "joblib.dump(model, filename)\n",
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "loaded_model = joblib.load(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dc2243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dff3bd2",
   "metadata": {},
   "source": [
    "# Sentment analysis using BERT finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2764d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation, Dense, Input\n",
    "\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import (BertTokenizer, BertForSequenceClassification, TFBertForSequenceClassification,\n",
    "                          CamembertTokenizer, CamembertForSequenceClassification, TFCamembertForSequenceClassification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb171acf",
   "metadata": {},
   "source": [
    "# Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b37765d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd84ddaf0ac4f5fae28e7fd4f83b630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CLOUDSEALS\\Anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\CLOUDSEALS\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757a6c7894ce4c9a9a9e7b4caeeef5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d7260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c89c6b79",
   "metadata": {},
   "source": [
    "# Load transformers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42b02697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb2f44dd8964c699c91af348c7d16d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ad78f7b44943b2a8180c3bc8d4cd7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertForSequenceClassification.\n",
      "\n",
      "Some layers of TFCamembertForSequenceClassification were not initialized from the model checkpoint at jplu/tf-camembert-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "transformers_model = TFCamembertForSequenceClassification.from_pretrained('jplu/tf-camembert-base', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92b81f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_camembert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " roberta (TFCamembertMainLay  multiple                 110031360 \n",
      " er)                                                             \n",
      "                                                                 \n",
      " classifier (TFCamembertClas  multiple                 592130    \n",
      " sificationHead)                                                 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110,623,490\n",
      "Trainable params: 110,623,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformers_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b21ab552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "News_data_lable['sent_len']= News_data_lable['News'].apply(lambda x: len(x.split(\" \")))\n",
    "max_seq_len = np.round(News_data_lable['sent_len'].mean() + 2 * News_data_lable['sent_len'].std()).astype(int)\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c8cc225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CLOUDSEALS\\AppData\\Local\\Temp\\ipykernel_18604\\3660869444.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for text in tqdm_notebook(News_data_lable['News']):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78630a13de4e44ff914aa722b842e7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\CLOUDSEALS\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_sequences = []\n",
    "# The attention mask is an optional argument used when batching sequences together.\n",
    "# The attention mask is a binary tensor indicating the position of the padded indices so that the model does not attend to them.\n",
    "attention_masks = []\n",
    "\n",
    "for text in tqdm_notebook(News_data_lable['News']):\n",
    "    sequence_dict = tokenizer.encode_plus(text, max_length=max_seq_len, pad_to_max_length=True)\n",
    "    input_ids = sequence_dict['input_ids']\n",
    "    att_mask = sequence_dict['attention_mask']\n",
    "\n",
    "    input_sequences.append(input_ids)\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2efaf06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 343, 92, 906, 640, 204, 92, 52, 11152, 110, 5225, 9, 29129, 253, 5349, 8476, 472, 906, 5406, 21746, 204, 1938, 18, 2408, 108, 11163, 669, 1280, 793, 996, 52, 11152, 110, 26, 234, 3058, 91, 4152, 442, 5472, 1895, 7, 5467, 13545, 10, 1782, 9477, 24537, 35, 9, 1723, 15502, 970, 816, 33, 10302, 10884, 91, 669, 7395, 2509, 67, 3047, 657, 9360, 133, 2509, 9, 310, 122, 10, 11152, 110, 17234, 10, 11152, 110, 17234, 4473, 10, 11387, 4480, 6434, 3770, 10, 16396, 33, 15267, 155, 105, 2446, 343, 185, 636, 816, 5444, 88, 9, 5467, 13545, 10, 6]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(input_sequences[0])\n",
    "print(attention_masks[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab69280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = News_data_lable['Label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c5609",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebb3f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, att_masks_train, att_masks_test = (\n",
    "    train_test_split(input_sequences, labels, attention_masks, random_state=42, test_size=0.2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f2b796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.constant(X_train)\n",
    "X_test = tf.constant(X_test)\n",
    "\n",
    "y_train = tf.constant(y_train)\n",
    "y_test = tf.constant(y_test)\n",
    "\n",
    "att_masks_train = tf.constant(att_masks_train)\n",
    "att_masks_test = tf.constant(att_masks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "147a096e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | X shape: (1620, 102), att_mask shape: (1620, 102), y shape: (1620,)\n",
      "Test | X shape: (405, 102), att_mask shape: (405, 102), y shape: (405,),\n"
     ]
    }
   ],
   "source": [
    "print(f'Train | X shape: {X_train.shape}, att_mask shape: {att_masks_train.shape}, y shape: {y_train.shape}')\n",
    "print(f'Test | X shape: {X_test.shape}, att_mask shape: {att_masks_test.shape}, y shape: {y_test.shape},')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f5b05c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = TFCamembertForSequenceClassification.from_pretrained('jplu/tf-camembert-base', num_labels=2)\n",
    "    \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    opt = tf.keras.optimizers.Adam(lr=2e-5)\n",
    "  \n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17599f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertForSequenceClassification.\n",
      "\n",
      "Some layers of TFCamembertForSequenceClassification were not initialized from the model checkpoint at jplu/tf-camembert-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_camembert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " roberta (TFCamembertMainLay  multiple                 110031360 \n",
      " er)                                                             \n",
      "                                                                 \n",
      " classifier (TFCamembertClas  multiple                 592130    \n",
      " sificationHead)                                                 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110,623,490\n",
      "Trainable params: 110,623,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f582b01",
   "metadata": {},
   "source": [
    "# Test Model before finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab50c2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before training: 0.6978, Accuracy before training: 40.25%\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate([X_test, att_masks_test], y_test, batch_size=32, verbose=0)\n",
    "print(f\"Loss before training: {loss:.4f}, Accuracy before training: {metric:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03395358",
   "metadata": {},
   "source": [
    "# Finetune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d9b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "51/51 [==============================] - 1168s 23s/step - loss: 0.6577 - accuracy: 0.6352 - val_loss: 0.6953 - val_accuracy: 0.5753\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 2455s 48s/step - loss: 0.6595 - accuracy: 0.6352 - val_loss: 0.6829 - val_accuracy: 0.5753\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 3357s 66s/step - loss: 0.6609 - accuracy: 0.6352 - val_loss: 0.6871 - val_accuracy: 0.5753\n",
      "Epoch 4/10\n",
      "51/51 [==============================] - 3366s 66s/step - loss: 0.6584 - accuracy: 0.6352 - val_loss: 0.6884 - val_accuracy: 0.5753\n",
      "Epoch 5/10\n",
      "51/51 [==============================] - 3603s 71s/step - loss: 0.6599 - accuracy: 0.6352 - val_loss: 0.6962 - val_accuracy: 0.5753\n",
      "Epoch 6/10\n",
      "51/51 [==============================] - 222020s 4439s/step - loss: 0.6600 - accuracy: 0.6352 - val_loss: 0.7101 - val_accuracy: 0.5753\n",
      "Epoch 7/10\n",
      " 4/51 [=>............................] - ETA: 25:55 - loss: 0.6485 - accuracy: 0.6562"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train, att_masks_train], y_train, batch_size=32, epochs=10, validation_data=([X_test, att_masks_test], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004021c",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0236da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    # pre-process text\n",
    "    encoded_text = tokenizer.encode(text)\n",
    "\n",
    "    input_ = tf.expand_dims(encoded_text, 0)\n",
    "\n",
    "    logits = model(input_)[0][0]\n",
    "    pred = tf.nn.softmax(logits)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c788bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Adani Green Energy Ltd has lost 14.81% over last one month compared to 0.25% fall in S&P BSE Utilities index and 2.48% drop in the SENSEX\"\n",
    "predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb3524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b1842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff64c68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37.539075,
   "end_time": "2021-07-14T07:12:17.839479",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-14T07:11:40.300404",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
